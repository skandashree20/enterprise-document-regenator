{
  "name": "21 - Document Updater",
  "nodes": [
    {
      "parameters": {},
      "id": "trigger-node",
      "name": "Execute Workflow Trigger",
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1,
      "position": [
        0,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Extract key topics from document for targeted research\nconst item = $input.first().json;\nconst analysis = item.analysis || {};\nconst extractedText = item.extracted_text || '';\nconst enrichmentData = item.enrichment_data || {};\nconst companySnippet = item.company_snippet || '';\n\n// Build search queries based on document content\nconst searchTopics = [];\n\n// From analysis themes\nif (analysis.themes && analysis.themes.length > 0) {\n  searchTopics.push(...analysis.themes.slice(0, 3));\n}\n\n// From entities\nif (analysis.entities) {\n  if (analysis.entities.products) searchTopics.push(...analysis.entities.products.slice(0, 2));\n  if (analysis.entities.technologies) searchTopics.push(...analysis.entities.technologies.slice(0, 2));\n}\n\n// From compliance mentions\nif (analysis.edtech_relevance?.compliance_mentions) {\n  searchTopics.push(...analysis.edtech_relevance.compliance_mentions);\n}\n\n// Deduplicate and limit\nconst uniqueTopics = [...new Set(searchTopics)].slice(0, 5);\n\n// Generate search queries\nconst searchQueries = uniqueTopics.map(topic => {\n  // Add context for better search results\n  if (topic.toLowerCase().includes('ferpa')) return 'FERPA compliance updates 2024 2025';\n  if (topic.toLowerCase().includes('soc')) return 'SOC 2 compliance requirements updates';\n  if (topic.toLowerCase().includes('transcript')) return 'academic transcript processing technology updates';\n  if (topic.toLowerCase().includes('airr')) return 'AIRR transcript automation higher education';\n  return `${topic} higher education EdTech updates 2024 2025`;\n});\n\nreturn [{\n  json: {\n    file_id: item.file_id,\n    file_name: item.file_name,\n    original_text: extractedText,\n    analysis: analysis,\n    search_topics: uniqueTopics,\n    search_queries: searchQueries,\n    output_folder_id: item.output_folder_id || item.config?.output_folder_id || '',\n    // Pass through enrichment data and company snippet\n    enrichment_data: enrichmentData,\n    company_snippet: companySnippet,\n    research_started: new Date().toISOString()\n  }\n}];"
      },
      "id": "extract-topics",
      "name": "Extract Research Topics",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        220,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Prepare search requests for each query\nconst item = $input.first().json;\nconst queries = item.search_queries || [];\n\n// Preserve parent data including enrichment context\nconst parentData = {\n  file_id: item.file_id,\n  file_name: item.file_name,\n  original_text: item.original_text,\n  analysis: item.analysis,\n  search_topics: item.search_topics,\n  output_folder_id: item.output_folder_id,\n  enrichment_data: item.enrichment_data || {},\n  company_snippet: item.company_snippet || ''\n};\n\nif (queries.length === 0) {\n  return [{\n    json: {\n      ...parentData,\n      search_results: [],\n      skip_reason: 'No search topics identified'\n    }\n  }];\n}\n\n// Return items for each search query\nreturn queries.map((query, index) => ({\n  json: {\n    query: query,\n    query_index: index,\n    parent_data: parentData\n  }\n}));"
      },
      "id": "prepare-searches",
      "name": "Prepare Search Requests",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        440,
        0
      ]
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://google.serper.dev/search",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify({ q: $json.query, num: 5 }) }}",
        "options": {
          "timeout": 30000
        }
      },
      "id": "serper-search",
      "name": "Serper Search API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        660,
        0
      ],
      "credentials": {
        "httpHeaderAuth": {
          "id": "kK1GI05nBZrYdskn",
          "name": "Serper API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "jsCode": "// Parse Serper search results\nconst item = $input.first();\nconst parentData = item.json.parent_data || $('Prepare Search Requests').first().json.parent_data;\nconst query = item.json.query || item.json.parent_data?.query || '';\n\nlet results = [];\ntry {\n  // Serper returns organic results in 'organic' array\n  const organicResults = item.json.organic || [];\n  results = organicResults.slice(0, 3).map(r => ({\n    title: r.title || '',\n    description: r.snippet || r.description || '',\n    url: r.link || r.url || '',\n    date: r.date || ''\n  }));\n  \n  // Also check for knowledge graph or answer box\n  if (item.json.answerBox) {\n    results.unshift({\n      title: item.json.answerBox.title || 'Featured Answer',\n      description: item.json.answerBox.snippet || item.json.answerBox.answer || '',\n      url: item.json.answerBox.link || '',\n      date: ''\n    });\n  }\n} catch (e) {\n  results = [];\n}\n\nreturn [{\n  json: {\n    query: query,\n    results: results,\n    parent_data: parentData\n  }\n}];"
      },
      "id": "parse-search",
      "name": "Parse Search Results",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        880,
        0
      ]
    },
    {
      "parameters": {
        "aggregate": "aggregateAllItemData",
        "destinationFieldName": "all_search_results",
        "options": {}
      },
      "id": "aggregate-searches",
      "name": "Aggregate Search Results",
      "type": "n8n-nodes-base.aggregate",
      "typeVersion": 1,
      "position": [
        1100,
        0
      ]
    },
    {
      "parameters": {
        "jsCode": "// Combine all search results with original document and enrichment context\nconst item = $input.first().json;\nconst allResults = item.all_search_results || [];\n\n// Get parent data from first result\nconst parentData = allResults[0]?.parent_data || {};\nconst enrichmentData = parentData.enrichment_data || {};\nconst companySnippet = parentData.company_snippet || '';\n\n// Compile document-specific research findings\nconst researchFindings = allResults.map(r => ({\n  query: r.query,\n  findings: r.results || []\n})).filter(r => r.findings.length > 0);\n\n// Format document-specific findings as text for LLM\nlet findingsText = '';\nfor (const finding of researchFindings) {\n  findingsText += `\\n### Research: ${finding.query}\\n`;\n  for (const f of finding.findings) {\n    findingsText += `- **${f.title}**: ${f.description}\\n`;\n  }\n}\n\n// Format pre-fetched enrichment data\nlet enrichmentText = '\\n## PRE-FETCHED INDUSTRY CONTEXT\\n';\n\nif (enrichmentData.edtech_news && enrichmentData.edtech_news.length > 0) {\n  enrichmentText += '\\n### EdTech Industry News\\n';\n  enrichmentData.edtech_news.slice(0, 3).forEach(item => {\n    enrichmentText += `- **${item.title}**: ${item.snippet}\\n`;\n  });\n}\n\nif (enrichmentData.ferpa_updates && enrichmentData.ferpa_updates.length > 0) {\n  enrichmentText += '\\n### FERPA & Compliance Updates\\n';\n  enrichmentData.ferpa_updates.slice(0, 3).forEach(item => {\n    enrichmentText += `- **${item.title}**: ${item.snippet}\\n`;\n  });\n}\n\nif (enrichmentData.higher_ed_trends && enrichmentData.higher_ed_trends.length > 0) {\n  enrichmentText += '\\n### Higher Education Trends\\n';\n  enrichmentData.higher_ed_trends.slice(0, 3).forEach(item => {\n    enrichmentText += `- **${item.title}**: ${item.snippet}\\n`;\n  });\n}\n\nif (enrichmentData.ai_tech_news && enrichmentData.ai_tech_news.length > 0) {\n  enrichmentText += '\\n### AI & Technology News\\n';\n  enrichmentData.ai_tech_news.slice(0, 3).forEach(item => {\n    enrichmentText += `- **${item.title}**: ${item.snippet}\\n`;\n  });\n}\n\n// Check if we have any context\nconst hasEnrichment = (enrichmentData.edtech_news?.length > 0) || \n                      (enrichmentData.ferpa_updates?.length > 0) ||\n                      (enrichmentData.higher_ed_trends?.length > 0) ||\n                      (enrichmentData.ai_tech_news?.length > 0);\n\nconst hasFindings = researchFindings.length > 0 || hasEnrichment;\n\nreturn [{\n  json: {\n    file_id: parentData.file_id,\n    file_name: parentData.file_name,\n    original_text: parentData.original_text,\n    analysis: parentData.analysis,\n    search_topics: parentData.search_topics,\n    output_folder_id: parentData.output_folder_id,\n    research_findings: researchFindings,\n    research_findings_text: findingsText,\n    enrichment_data: enrichmentData,\n    enrichment_text: hasEnrichment ? enrichmentText : '',\n    company_snippet: companySnippet,\n    has_findings: hasFindings\n  }\n}];"
      },
      "id": "compile-research",
      "name": "Compile Research",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1320,
        0
      ]
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "strict"
          },
          "conditions": [
            {
              "id": "has-findings",
              "leftValue": "={{ $json.has_findings }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "options": {}
      },
      "id": "check-findings",
      "name": "Has Research Findings?",
      "type": "n8n-nodes-base.if",
      "typeVersion": 2,
      "position": [
        1540,
        0
      ]
    },
    {
      "parameters": {
        "model": "gpt-4o",
        "messages": {
          "values": [
            {
              "role": "system",
              "content": "You are a document update specialist for OneOrigin, an EdTech company. Your task is to:\n\n1. Compare the original document content with recent research findings AND industry context\n2. Identify sections that are outdated or could benefit from updates\n3. Generate an updated version of the document incorporating new information\n4. Ensure updates align with OneOrigin's company identity and messaging\n\nGuidelines:\n- Preserve the original document structure and tone\n- Only update sections where new information adds value\n- Clearly mark what was updated with [UPDATED] tags\n- Add sources/references for new information\n- Focus on: compliance updates (especially FERPA), technology changes, AI/EdTech trends, higher education developments\n- Ensure consistency with the company snippet/identity provided\n- Prioritize updates that strengthen OneOrigin's positioning in higher education and EdTech\n\nRespond with JSON containing:\n- needs_update: boolean\n- update_summary: brief description of changes\n- updated_sections: array of {section_name, original, updated, reason}\n- updated_document: full updated document text\n- sources: array of sources used"
            },
            {
              "role": "user",
              "content": "=Review this document and update it based on research findings and industry context:\n\n## COMPANY IDENTITY\n{{ $json.company_snippet || 'OneOrigin is an EdTech company specializing in higher education solutions.' }}\n\n---\n\n## ORIGINAL DOCUMENT\nFile: {{ $json.file_name }}\n\n{{ $json.original_text.substring(0, 12000) }}\n\n---\n\n## DOCUMENT-SPECIFIC RESEARCH\n{{ $json.research_findings_text }}\n\n---\n\n{{ $json.enrichment_text }}\n\n---\n\nAnalyze the document, compare with all research findings and industry context, and provide updates where relevant. Ensure any updates align with the company identity. If no updates are needed, set needs_update to false."
            }
          ]
        },
        "options": {
          "temperature": 0.3,
          "maxTokens": 8000,
          "responseFormat": "json_object"
        }
      },
      "id": "analyze-updates",
      "name": "Analyze & Generate Updates",
      "type": "@n8n/n8n-nodes-langchain.openAi",
      "typeVersion": 1.8,
      "position": [
        1760,
        -100
      ],
      "credentials": {
        "openAiApi": {
          "id": "CJCFB3T7mvekmbpe",
          "name": "OpenAI API"
        }
      },
      "continueOnFail": true
    },
    {
      "parameters": {
        "jsCode": "// Parse update analysis and prepare output\nconst item = $input.first();\nconst originalData = $('Compile Research').first().json;\nlet updateResult = null;\n\ntry {\n  const response = item.json.message?.content || item.json.text || item.json.output || '';\n  updateResult = typeof response === 'string' ? JSON.parse(response) : response;\n} catch (e) {\n  updateResult = {\n    needs_update: false,\n    update_summary: 'Failed to parse update analysis',\n    error: e.message\n  };\n}\n\nconst needsUpdate = updateResult.needs_update === true;\nconst updatedContent = needsUpdate ? updateResult.updated_document : originalData.original_text;\n\nreturn [{\n  json: {\n    file_id: originalData.file_id,\n    file_name: originalData.file_name,\n    original_file_name: originalData.file_name,\n    needs_update: needsUpdate,\n    update_summary: updateResult.update_summary || 'No updates needed',\n    updated_sections: updateResult.updated_sections || [],\n    sources: updateResult.sources || [],\n    \n    // For upload\n    document_type: 'updated_document',\n    title: `Updated: ${originalData.file_name}`,\n    content: updatedContent,\n    file_name: needsUpdate \n      ? originalData.file_name.replace(/\\.[^/.]+$/, '') + '_updated_' + new Date().toISOString().split('T')[0] + '.md'\n      : null,\n    output_folder_id: originalData.output_folder_id,\n    \n    status: needsUpdate ? 'updated' : 'no_update_needed',\n    processed_at: new Date().toISOString()\n  }\n}];"
      },
      "id": "format-update",
      "name": "Format Update Result",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1980,
        -100
      ]
    },
    {
      "parameters": {
        "jsCode": "// No research findings - return original document unchanged\nconst item = $input.first().json;\n\nreturn [{\n  json: {\n    file_id: item.file_id,\n    file_name: item.file_name,\n    original_file_name: item.file_name,\n    needs_update: false,\n    update_summary: 'No relevant research findings to compare',\n    updated_sections: [],\n    sources: [],\n    \n    document_type: 'original_document',\n    title: item.file_name,\n    content: item.original_text,\n    file_name: null,\n    output_folder_id: item.output_folder_id,\n    \n    status: 'no_research_available',\n    processed_at: new Date().toISOString()\n  }\n}];"
      },
      "id": "no-findings",
      "name": "No Updates Available",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1760,
        100
      ]
    },
    {
      "parameters": {},
      "id": "merge-output",
      "name": "Merge Output",
      "type": "n8n-nodes-base.merge",
      "typeVersion": 3,
      "position": [
        2200,
        0
      ]
    }
  ],
  "connections": {
    "Execute Workflow Trigger": {
      "main": [
        [
          {
            "node": "Extract Research Topics",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Research Topics": {
      "main": [
        [
          {
            "node": "Prepare Search Requests",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Search Requests": {
      "main": [
        [
          {
            "node": "Serper Search API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Serper Search API": {
      "main": [
        [
          {
            "node": "Parse Search Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Search Results": {
      "main": [
        [
          {
            "node": "Aggregate Search Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Aggregate Search Results": {
      "main": [
        [
          {
            "node": "Compile Research",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Compile Research": {
      "main": [
        [
          {
            "node": "Has Research Findings?",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Has Research Findings?": {
      "main": [
        [
          {
            "node": "Analyze & Generate Updates",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "No Updates Available",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Analyze & Generate Updates": {
      "main": [
        [
          {
            "node": "Format Update Result",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Update Result": {
      "main": [
        [
          {
            "node": "Merge Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "No Updates Available": {
      "main": [
        [
          {
            "node": "Merge Output",
            "type": "main",
            "index": 1
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "tags": [
    {
      "name": "processing"
    }
  ],
  "triggerCount": 0,
  "updatedAt": "2024-01-01T00:00:00.000Z",
  "versionId": "1",
  "active": false
}